#!/usr/bin/env python3

from typing import Any, Dict, List, Optional, Sequence
from datetime import datetime
from pathlib import Path
import gzip, json, shlex, shutil, subprocess, sys, time
import signal
import os
import config, slack

def log(msg: str) -> None:
    print(msg, flush=True)

def format_time(ts: float) -> str:
    t = float(ts)
    if t < 120:
        return f"{t:.1f}s"
    elif t < 120*60:
        return f"{t/60:.1f}m"
    else:
        return f"{t/60/60:.1f}h"

def format_cmd(s: Sequence[str | Path]) -> str:
    return shlex.join([str(part) for part in s])

def run(cmd: Sequence[str | Path], **kwargs: Any) -> subprocess.CompletedProcess[bytes]:
    log(f"Executing {format_cmd(cmd)}")
    return subprocess.run(cmd, **kwargs)

def parse_time(to: str | None) -> float | None:
    if to is None:
        return to
    units = {"hr": 3600, "h": 3600, "min": 60, "m": 60, "sec": 1, "s": 1}
    for unit, multiplier in units.items():
        if to.endswith(unit):
            return float(to[:-len(unit)]) * multiplier
    return float(to)

def format_size(size: int) -> str:
    units = ["KB", "MB", "GB", "TB", "PB"]
    s = float(size) / 1024
    for unit in units:
        if s < 1024:
            break
        s /= 1024
    return f"{s:.2f}{unit}"

def tree_size(root: Path) -> tuple[int, Path | None, int]:
    total = 0
    biggest = None
    biggest_size = 0
    for dirpath, _, files in root.walk():
        for name in files:
            path = dirpath / name
            size = path.lstat().st_size
            total += size
            if size > biggest_size:
                biggest_size = size
                biggest = path
    return total, biggest and biggest.relative_to(root), biggest_size

def copything(src: Path, dst: Path) -> None:
    if src.is_dir():
        shutil.copytree(src, dst)
    else:
        shutil.copy2(src, dst)

def gzip_matching_files(directory: Path, globs: List[str]) -> None:
    for path in directory.rglob("*"):
        if path.is_file() and any(path.match(g) for g in globs):
            gz_path = path.with_suffix(path.suffix + ".gz")
            with path.open("rb") as f_in, gzip.open(gz_path, "wb", compresslevel=9) as f_out:
                shutil.copyfileobj(f_in, f_out)
            path.unlink()

def read_metadata(metadata_file: Path) -> Dict[str, Any]:
    if metadata_file.exists():
        with metadata_file.open() as f:
            try:
                data: Dict[str, Any] = json.load(f)
                return data
            except json.JSONDecodeError:
                pass
    return {}

def save_metadata(metadata_file: Path, data: Dict[str, Any]) -> None:
    with metadata_file.open("w") as f:
        json.dump(data, f)

def run_branch(bc: config.BranchConfig, log_name: str) -> int:
    log(f"Running branch {bc.branch_name} on repo {bc.repo_name}")
    info: Dict[str, str] = {}
    slack_output = slack.make_output(bc.config.secrets, bc.slack_spec, bc.repo_name)
    start: Optional[datetime] = None

    if bc.base_url:
        import urllib.parse
        info["logurl"] = bc.base_url + "logs/" + urllib.parse.quote(log_name)

    def handle_sigterm(signum, frame):
        log(f"Received signal {signum}")
        info["result"] = "*killed*"
        if start is not None:
            info["time"] = format_time((datetime.now() - start).seconds)
        log("Posting killed result to slack")
        if slack_output:
            try:
                slack_output.post(bc.branch_name, info)
            except slack.SlackError as e:
                log(f"Slack error: {e}")
        raise SystemExit(128 + signum)

    signal.signal(signal.SIGTERM, handle_sigterm)

    run(["git", "-C", bc.branch_dir, "reset", "--hard", f"origin/{bc.branch_name}"], check=True)
    run(["git", "-C", bc.branch_dir, "submodule", "update", "--init", "--recursive", "--force"], check=True)

    out = run(
        ["git", "-C", bc.branch_dir, "rev-parse", f"origin/{bc.branch_name}"],
        capture_output=True, check=True
    ).stdout.decode("ascii").strip()

    start = datetime.now()
    try:
        to = parse_time(bc.timeout)
        cmd = ["make", "-C", str(bc.branch_dir), "nightly"]
        
        if bc.report_dir:
            if bc.report_dir.exists():
                shutil.rmtree(bc.report_dir, ignore_errors=True)
            bc.report_dir.mkdir(parents=True, exist_ok=True)

        result = run(cmd, timeout=to)
        if result.returncode:
            raise subprocess.CalledProcessError(result.returncode, cmd)

    except subprocess.TimeoutExpired as e:
        log(f"Run on branch {bc.branch_name} timed out after {format_time(e.timeout)}")
        failure = "timeout"
    except subprocess.CalledProcessError:
        failure = "failure"
    else:
        log(f"Successfully ran on branch {bc.branch_name}")
        failure = ""

    metadata = read_metadata(bc.metadata_file)
    metadata["commit"] = out
    metadata["time"] = time.time()
    save_metadata(bc.metadata_file, metadata)

    if bc.report_dir and bc.report_dir.exists():
        try:
            if bc.gzip:
                log(f"GZipping all {bc.gzip} files")
                gzip_matching_files(bc.report_dir, shlex.split(bc.gzip))

            total, biggest, _ = tree_size(bc.report_dir)
            if bc.warn_report and total > bc.warn_report:
                msg = (
                    f"Report size {format_size(total)} exceeds limit {format_size(bc.warn_report)}"
                    f"; largest file `{biggest}`"
                )
                log(f"Report `{bc.branch_name}` is {format_size(total)}; largest file `{biggest}`")
                if slack_output:
                    slack_output.warn("report-size", msg)

            if "url" not in info and bc.base_url:
                name = f"{int(time.time())}:{bc.branch_filename}:{out[:8]}"
                dest_dir = bc.reports_dir / bc.repo_name / name

                if bc.report_dir.exists():
                    log(f"Publishing report directory {bc.report_dir} to {dest_dir}")
                    copything(bc.report_dir, dest_dir)
                    url_base = bc.base_url + "reports/" + bc.repo_name + "/" + name
                    info["url"] = url_base
                    if bc.image_file and bc.image_file.exists():
                        log(f"Linking image file {bc.image_file}")
                        path = bc.image_file.relative_to(bc.report_dir)
                        info["img"] = url_base + "/" + str(path)
                    shutil.rmtree(bc.report_dir, ignore_errors=True)
                else:
                    log(f"Report directory {bc.report_dir} does not exist")
        except OSError as e:
            msg = f"Error saving report: {e}"
            log(f"Error saving report for `{bc.branch_name}`: {e}")
            if slack_output:
                slack_output.warn("broken-report", msg)

    total, biggest, _ = tree_size(bc.branch_dir)
    if bc.warn_branch and total > bc.warn_branch:
        msg = (
            f"Branch size {format_size(total)} exceeds limit {format_size(bc.warn_branch)}"
            f"; largest file `{biggest}`"
        )
        log(msg)
        if slack_output:
            slack_output.warn("branch-size", msg)

    log_file = bc.logs_dir / log_name
    size = log_file.stat().st_size if log_file.exists() else 0
    if bc.warn_log and size > bc.warn_log:
        msg = (
            f"Log size {format_size(size)} exceeds limit {format_size(bc.warn_log)}"
        )
        log(msg)
        if slack_output:
            slack_output.warn("log-size", msg)

    info["result"] = f"*{failure}*" if failure else "success"
    info["time"] = format_time((datetime.now() - start).seconds)

    if slack_output:
        log("Posting results of run to slack!")
        try:
            slack_output.post(bc.branch_name, info)
        except slack.SlackError as e:
            log(f"Slack error: {e}")

    job_id = os.environ.get("SLURM_JOB_ID")
    assert job_id is not None
    output = run(
        ["sstat", "--noheader", "-j", f"{job_id}.batch", "--format=MaxRSS,Elapsed"],
        capture_output=True, check=True,
    ).stdout.decode("ascii", errors="replace").strip()
    assert output, f"sstat returned empty line: {output!r}"
    assert "\n" not in output, f"sstat returned multiple lines: {output!r}"
    max_rss_str, elapsed = output.split()
    max_rss = config.parse_size(max_rss_str.lower())
    assert max_rss is not None, f"sstat returned unknown MaxRSS: {max_rss_str!r}"
    log(f"Nightly used memory={format_size(max_rss).lower()}, elapsed={elapsed}")

    return 1 if failure else 0


def main() -> int:
    if len(sys.argv) != 5:
        print(f"Usage: {sys.argv[0]} <config_file> <repo> <branch> <log_name>", file=sys.stderr, flush=True)
        return 2

    config_file, repo, branch, log_name = sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4]
    cfg = config.Config(config_file)
    bc = config.BranchConfig(cfg, repo, branch)
    return run_branch(bc, log_name)


if __name__ == "__main__":
    sys.exit(main())
